{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative models은 새로운 데이터를 생성하는 것이다. 이전에 다루었던 모델과는 반대되는 모델이다. 이미지 분류 모델에서는 고차원의 입력을 받고, 이미지 내용과도 같은 저차원을 출력한다. \n",
    "\n",
    "2017년에 Deepfakes가 인터넷에 떠돌기 시작했다. GANs이 유명인들을 features하여 포르노 비디오를 생성하는데 사용되었다. 2016년에 연구자들은 정치인들이 연설하는 비디오를 입모양과 얼굴 표정까지 완벽하게 표현하는 비디오를 만들었다.\n",
    "\n",
    "이 기술은 부정적인 부분만 있는 것은 아니다. sparse한 데이터를 생성하는데 있어 긍정적으로 쓰일 수 있다. 이 경우에 Generative models은 다른 모델이 학습할 수 있는 리얼한 데이터를 생성할 수 있다. Generative models은 이미지를 translate할 수 있다. 위성 사진을 스트릿 사진으로 변환할 수 있다. 또 다른 예로 website screenshot에서 code를 생성할 수도 있다. Generative model은 ML 모델의 unfairness와 discrimination을 다루는데도 사용할 수 있다.\n",
    "\n",
    "금융 분야에서 data가 sparse한 경우가 있다. 데이터를 생성하여 유용한 features를 찾을 수 있다.\n",
    "\n",
    "알고리즘 트레이딩에서 시뮬레이터에 의해서 데이터가 생성된다. 만약 만든 알고리즘이 global selloff에서 어떻게 하는지 알고 싶을 수 있을 것이다. 그러나 global selloff는 많이 생기진 않는다. 그렇기 때문에 퀀트들은 보통 global selloff 시뮬레이터를 만드는데 많은 시간을 쓴다. 이 시뮬레이터는 엔지니어의 경험과 그들의 느낌적 느낌에 의해 global selloff가 편향될 수 있다. 하지만, 만약 모델이 global selloff의 펀더멘탈을 배울 수 있다면 어떨까? 그리고 무한한 global selloff를 만들 수 있다면 어떨까?\n",
    "\n",
    "이번에는 autoencoder와 GANs을 알아보겠다. autoencoder는 저차원으로 데이터를 압축하고 데이터를 충실하게 재구성한다. GANs은 discriminator가 가짜 이미지와 진짜 이미지를 구별할 수 없도록 generator를 훈련시킨다. \n",
    "\n",
    "### understanding autoencoders\n",
    "\n",
    "기술적으로 autoencoders는 새로운 종류의 데이터를 생성할 수 없기 때문에 generative models은 아니다. 그러나 autoencoder를 조금 변형하면 가능하다. \n",
    "\n",
    "금융 분야에 초점을 둔다면, autoencoders는 신용카드사기 detecting과 같은 애플리케이션을 위한 흥미로운 속성을 가지고 있다. \n",
    "\n",
    "입력 x가 주어질 때 autoencoder는 출력 x를 학습니다. autoencoder는 함수 f를 찾는데 아래의 식이 참이 되도록 하는 것을 찾는다.\n",
    "\n",
    "$$x = f(x)$$\n",
    "\n",
    "별거없어 보일지 모르지만, 여기서 트릭은 autoencoder는 bottleneck을 가지고 있다는 것이다. middle hidden layer의 사이즈는 입력 x의 사이즈보다 작다. 그렇기에 모델은 작은 vector에 x의 중요한 모든 요소를 캡처하기 위해 compressed representation을 학습해야 한다. \n",
    "\n",
    "아래의 그림이 autoencoder의 compressed representation schema(개요)를 잘 보여준다.\n",
    "![nn](https://miro.medium.com/max/528/1*Fm7RPNckepfCgLKtkKfskQ.png)\n",
    "![nn](https://miro.medium.com/max/528/1*FGbATgGye0fTU9SMaCo16A.png)\n",
    "\n",
    "이 compressed representation은 입력의 essence를 캡처하는 것이 목적이다. 예를 들어, genuine one한 것에서 부터 사기 거래를 구별하는 본질적인 것을 캡처하고 싶을 수 있다. Vanila autoencoders는 standard principal component analysis와 비슷한 느낌으로 수행한다. 데이터에서 차원을 줄이고 중요한 것에 집중한다. 그러나 PCA와는 다르게, autoencoder는 특정 type의 데이터를 더 생성하도록 확장할 수 있다. 예를 들어, autoencoder는 이미지나 비디오 데이터를 더 잘 다룰 수 있는데 convolutional layer를 사용하여 데이터의 spatiality를 이용할 수 있다. \n",
    "\n",
    "두개의 autoencoder 모델을 만들어 보겠다. 첫번째 모델은 MNIST 데이터를 사용한다. 두번째는 사기 탐지 작업을 위해 사용할 것이다. \n",
    "\n",
    "### Autoencoder for MNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
